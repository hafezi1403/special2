{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPVOSiSQJ3zNUrW78dsdLKE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hafezi1403/special2/blob/main/Hafezi_26_01_1404_Chapter6_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToHRUCXl_85x",
        "outputId": "0cdb0240-f48f-47ba-9c99-4cdd6f4548c9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Interrobang. By Aishwarya Henriette',\n",
              " 'Parking And Going. By Karl Gautier',\n",
              " 'Today Is The night. By Jarek Prakash']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# Create text\n",
        "text_data = [\" Interrobang. By Aishwarya Henriette \",\n",
        "\"Parking And Going. By Karl Gautier\",\n",
        "\" Today Is The night. By Jarek Prakash \"]\n",
        "# Strip whitespaces\n",
        "strip_whitespace = [string.strip() for string in text_data]\n",
        "# Show text\n",
        "strip_whitespace"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove periods\n",
        "remove_periods = [string.replace(\".\", \"\") for string in strip_whitespace]"
      ],
      "metadata": {
        "id": "HTcKYFVPAumu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show text\n",
        "remove_periods"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKHL95CIAyPu",
        "outputId": "606f300d-1ca3-41a0-a193-dd2cef91b800"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Interrobang By Aishwarya Henriette',\n",
              " 'Parking And Going By Karl Gautier',\n",
              " 'Today Is The night By Jarek Prakash']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create function\n",
        "def capitalizer(string: str) -> str:\n",
        "  return string.upper()"
      ],
      "metadata": {
        "id": "TuyKlghyA1IH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply function\n",
        "[capitalizer(string) for string in remove_periods]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1JHhLYRBJNq",
        "outputId": "e7a49380-f842-4106-da02-130896aeefbf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['INTERROBANG BY AISHWARYA HENRIETTE',\n",
              " 'PARKING AND GOING BY KARL GAUTIER',\n",
              " 'TODAY IS THE NIGHT BY JAREK PRAKASH']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import library\n",
        "import re\n",
        "# Create function\n",
        "def replace_letters_with_X(string: str) -> str:\n",
        "  return re.sub(r\"[a-zA-Z]\", \"X\", string)"
      ],
      "metadata": {
        "id": "3AamgvAPBTvZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply function\n",
        "[replace_letters_with_X(string) for string in remove_periods]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TKeEgkMB9AV",
        "outputId": "41d2c693-9441-4688-f554-9c00aca81139"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['XXXXXXXXXXX XX XXXXXXXXX XXXXXXXXX',\n",
              " 'XXXXXXX XXX XXXXX XX XXXX XXXXXXX',\n",
              " 'XXXXX XX XXX XXXXX XX XXXXX XXXXXXX']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a string\n",
        "s = \"machine learning in python cookbook\"\n",
        "# Find the first index of the letter \"n\"\n",
        "find_n = s.find(\"n\")"
      ],
      "metadata": {
        "id": "jHuoMc0OCY7V"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "find_n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVCwuiOeCa2F",
        "outputId": "1b94c737-8a69-4dd9-8d96-6c357dce947e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a string\n",
        "s = \"machine learning in python cookbook\"\n",
        "# Whether or not the string starts with \"m\"\n",
        "starts_with_m = s.startswith(\"m\")"
      ],
      "metadata": {
        "id": "BxmAeuyXCiQG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "starts_with_m,"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6Gh7AlqCqtV",
        "outputId": "97a995e3-ba6a-45fa-a6f5-f9906e0f52a6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True,)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a string\n",
        "s = \"machine learning in python cookbook\"\n",
        "# Whether or not the string ends with \"python\"\n",
        "ends_with_python = s.endswith(\"python\")"
      ],
      "metadata": {
        "id": "oVVzpi7KCvZt"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ends_with_python,"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcjSjewVC3ZV",
        "outputId": "8e705985-d745-4dc4-cc73-23c0607a4689"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(False,)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a string\n",
        "s = \"machine learning in python cookbook\"\n",
        "# Is the string alphanumeric\n",
        "is_alnum = s.isalnum()# Is it composed of only alphabetical characters (not including spaces)"
      ],
      "metadata": {
        "id": "r2xSPBl8C92l"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "is_alnum,"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyeD5sipDFmV",
        "outputId": "8dcd596c-707d-4053-e7fb-051576fa150f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(False,)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a string\n",
        "s = \"machine learning in python cookbook\"\n",
        "is_alpha = s.isalpha()"
      ],
      "metadata": {
        "id": "JccO6zSzDKcd"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "is_alpha,"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUVVfu6XDWb9",
        "outputId": "8b7cdd8a-54f9-47d7-b809-90f564634d80"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(False,)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a string\n",
        "s = \"machine learning in python cookbook\"\n",
        "# Encode as utf-8\n",
        "encode_as_utf8 = s.encode(\"utf-8\")"
      ],
      "metadata": {
        "id": "0mMeb4DeDbFM"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encode_as_utf8,"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPoLkb6EDgxF",
        "outputId": "37e3d485-f36e-48d4-9948-70837546f6c0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(b'machine learning in python cookbook',)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a string\n",
        "s = \"machine learning in python cookbook\"\n",
        "# Decode the same utf-8\n",
        "decode = encode_as_utf8.decode(\"utf-8\")"
      ],
      "metadata": {
        "id": "qgiYZ43aDkl1"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decode,"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3Sj4pqzDrzl",
        "outputId": "bf4d4f1b-50fa-4e15-d4ca-5fd8aa18ddda"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('machine learning in python cookbook',)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load library\n",
        "from bs4 import BeautifulSoup\n",
        "# Create some HTML code\n",
        "html = \"<div class='full_name'>\"\\\n",
        "\"<span style='font-weight:bold'>Masego\"\\\n",
        "\"</span> Azra</div>\"\n",
        "# Parse html\n",
        "soup = BeautifulSoup(html, \"lxml\")\n",
        "# Find the div with the class \"full_name\", show text\n",
        "soup.find(\"div\", { \"class\" : \"full_name\" }).text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qlfnj_UzD1EF",
        "outputId": "9ec253a9-0d04-47db-f2e9-0c94a2c6b95e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Masego Azra'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load libraries\n",
        "import unicodedata\n",
        "import sys\n",
        "# Create text\n",
        "text_data = ['Hi!!!! I. Love. This. Song....',\n",
        "'10000% Agree!!!! #LoveIT',\n",
        "'Right?!?!']\n",
        "# Create a dictionary of punctuation characters\n",
        "punctuation = dict.fromkeys(\n",
        "(i for i in range(sys.maxunicode)\n",
        "if unicodedata.category(chr(i)).startswith('P')\n",
        "),\n",
        "None\n",
        ")\n",
        "#For each string, remove any punctuation characters\n",
        "[string.translate(punctuation) for string in text_data]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fw0tg70zD-ns",
        "outputId": "466c2de2-fa4a-48ff-840e-684e6dec95b0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hi I Love This Song', '10000 Agree LoveIT', 'Right']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load library\n",
        "from nltk.tokenize import word_tokenize\n",
        "# Create text\n",
        "string = \"The science of today is the technology of tomorrow\"\n",
        "# Tokenize words\n",
        "word_tokenize(string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OkuBTD1E9xC",
        "outputId": "92ee9c51-6f83-41b6-8aad-6da12a34789b"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The', 'science', 'of', 'today', 'is', 'the', 'technology', 'of', 'tomorrow']"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load library\n",
        "from nltk.tokenize import sent_tokenize\n",
        "# Create text\n",
        "string = \"The science of today is the technology of tomorrow. Tomorrow is today.\"\n",
        "# Tokenize sentences\n",
        "sent_tokenize(string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_FeFonHFH-J",
        "outputId": "e8bab203-9a03-4fb4-e3a1-0f4bd7dd8d26"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The science of today is the technology of tomorrow.', 'Tomorrow is today.']"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWi1F5OOFStw",
        "outputId": "9533467b-9ced-4caf-aaa8-81f69fba8e83"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load library\n",
        "from nltk.corpus import stopwords\n",
        "# You will have to download the set of stop words the first time\n",
        "# import nltk\n",
        "# nltk.download('stopwords')\n",
        "# Create word tokens\n",
        "tokenized_words = ['i',\n",
        "'am',\n",
        "'going',\n",
        "'to',\n",
        "'go',\n",
        "'to',\n",
        "'the',\n",
        "'store',\n",
        "'and',\n",
        "'park']\n",
        "# Load stop words\n",
        "stop_words = stopwords.words('english')\n",
        "# Remove stop words\n",
        "[word for word in tokenized_words if word not in stop_words]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pFzk_oZFOuw",
        "outputId": "7c552f4d-28ea-4037-d519-441e311e4b3c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['going', 'go', 'store', 'park']"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show stop words\n",
        "stop_words[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2wz_d_uFiP_",
        "outputId": "ca7951ea-1030-4835-d792-c8d000b297dd"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a', 'about', 'above', 'after', 'again']"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load library\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "# Create word tokens\n",
        "tokenized_words = ['i', 'am', 'humbled', 'by', 'this', 'traditional', 'meeting']\n",
        "# Create stemmer\n",
        "porter = PorterStemmer()\n",
        "# Apply stemmer\n",
        "[porter.stem(word) for word in tokenized_words]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EDfqW7GFmjm",
        "outputId": "4f0ccbda-4bc6-47b8-a9d0-0b1b6f4296cb"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'am', 'humbl', 'by', 'thi', 'tradit', 'meet']"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    }
  ]
}